{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModel\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import torch\n",
    "import wandb\n",
    "from transformers import pipeline\n",
    "from datasets import DatasetDict, Dataset\n",
    "import llm_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "wandb.login(key=wandb_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file_path = r'./data/train_fi_twitter_data.csv'\n",
    "test_file_path = r'./data/valid_fi_twitter_data.csv'\n",
    "training_data = pd.read_csv(train_file_path)\n",
    "test_data = pd.read_csv(test_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_processed = llm_models.data_cleaning(training_data)\n",
    "test_data_processed = llm_models.data_cleaning(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices, valid_indices = train_test_split(\n",
    "    training_data_processed.index, test_size=0.2, random_state=42\n",
    ")\n",
    "train_data_processed = training_data_processed.loc[train_indices]\n",
    "valid_data_processed = training_data_processed.loc[valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    df = df[~df['label'].apply(lambda x: isinstance(x, list))]\n",
    "    df = df[['title', 'label']]\n",
    "    df = df.dropna()\n",
    "    df.columns = ['text', 'label']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = clean_df(train_data_processed)\n",
    "valid_data_processed = clean_df(valid_data_processed)\n",
    "test_data_processed = clean_df(test_data_processed)\n",
    "training_data_processed = clean_df(training_data_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label\n",
    "label_list = [\"Analyst Update\",  \"Fed and Central Banks\", \"Company and Product News\", \"Treasuries and Corporate Debt\", \"Dividend\", \"Earnings\", \"Energy and Oil\", \"Financials\", \"Currencies\", \"General News and Opinion\", \"Gold and Metals and Materials\", \"IPO\", \"Legal and Regulation\", \"M&A and Investments\", \"Macro\", \"Markets\", \"Politics\", \"Personnel Change\", \"Stock Commentary\", \"Stock Movement\"]\n",
    "# label mapping\n",
    "ids = range(len(label_list))\n",
    "id2label = dict(zip(ids, label_list))\n",
    "label2id = dict(zip(label_list, ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data_processed['text']\n",
    "y_train = training_data_processed['label']\n",
    "X_test = test_data_processed['text']\n",
    "y_test = test_data_processed['label']\n",
    "\n",
    "# Initialize a TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train a Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"Baseline Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Baseline F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for bert\n",
    "def encode_text(texts, tokenizer):\n",
    "    return tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        add_special_tokens=True,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "def get_inputs(data_processed, device, tokenizer):\n",
    "    texts = data_processed['text'].values.tolist()\n",
    "    inputs = encode_text(texts, tokenizer)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    inputs_tensor = TensorDataset(inputs['input_ids'], inputs['attention_mask'])\n",
    "    # dataloader = DataLoader(inputs_tensor, batch_size=batch_size, shuffle=False)\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs = get_inputs(training_data_processed, device, tokenizer)\n",
    "train_inputs = get_inputs(train_data_processed, device, tokenizer)\n",
    "valid_inputs = get_inputs(valid_data_processed, device, tokenizer)\n",
    "test_inputs = get_inputs(test_data_processed, device, tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "model.to(device)\n",
    "accuracy, f1 = llm_models.direct_classification(model, test_data_processed, test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(model_name, num_labels=len(label_list))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df_hidden = llm_models.get_hidden_states(training_inputs)\n",
    "test_df_hidden = llm_models.get_hidden_states(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = training_df_hidden\n",
    "y_train = training_data_processed['label'].values.tolist()\n",
    "\n",
    "x_test = test_df_hidden\n",
    "y_test = test_data_processed['label'].values.tolist()\n",
    "\n",
    "# Create a Logistic Regression model (or any other classifier)\n",
    "classifier = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the classifier\n",
    "classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = classifier.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f'Accuracy: {accuracy:.2f}%')\n",
    "print(f'F1 Score: {f1:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {key: value.cpu().numpy().tolist() if isinstance(value, torch.Tensor) else value\n",
    "              for key, value in train_inputs.items()}\n",
    "valid_dict = {key: value.cpu().numpy().tolist() if isinstance(value, torch.Tensor) else value\n",
    "              for key, value in valid_inputs.items()}\n",
    "test_dict = {key: value.cpu().numpy().tolist() if isinstance(value, torch.Tensor) else value\n",
    "             for key, value in test_inputs.items()}\n",
    "\n",
    "train_ds = Dataset.from_pandas(pd.DataFrame(train_dict))\n",
    "valid_ds = Dataset.from_pandas(pd.DataFrame(valid_dict))\n",
    "test_ds = Dataset.from_pandas(pd.DataFrame(test_dict))\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'valid': valid_ds,\n",
    "    'test': test_ds\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 10\n",
    "lr_initial_2 = 5e-6\n",
    "weight_decay_2 = 1e-2\n",
    "metrics_df_3 = llm_models.fine_tune_bert(model_name, 'earlyStop2', dataset_dict, num_train_epochs, lr_initial_2, weight_decay_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 10\n",
    "lr_initial_3 = 2e-6\n",
    "weight_decay_3 = 1e-2\n",
    "metrics_df_3 = llm_models.fine_tune_bert(model_name, 'earlyStop3', dataset_dict, num_train_epochs, lr_initial_3, weight_decay_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 4\n",
    "lr_initial_4 = 5e-5\n",
    "weight_decay_4 = 5e-2\n",
    "metrics_df_2 = llm_models.fine_tune_bert(model_name, 'earlyStop4', dataset_dict, num_train_epochs, lr_initial_4, weight_decay_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 4\n",
    "lr_initial_5 = 6e-5\n",
    "weight_decay_5 = 5e-3\n",
    "metrics_df_5 = llm_models.fine_tune_bert(model_name, 'earlyStop5', dataset_dict, num_train_epochs, lr_initial_5, weight_decay_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 4\n",
    "lr_initial_6 = 8e-6\n",
    "weight_decay_6 = 5e-3\n",
    "metrics_df_6 = llm_models.fine_tune_bert(model_name, 'earlyStop6', dataset_dict, num_train_epochs, lr_initial_6, weight_decay_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilGPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, num_labels=len(label_list), id2label=id2label, label2id=label2id)\n",
    "model.to(device)\n",
    "accuracy, f1 = llm_models.direct_classification(model, test_data_processed, test_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prompt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic \n",
    "base_prompt_template = \"\"\"\n",
    "Please classify the text into one of the following financial categories:\n",
    "Analyst Update, Fed and Central Banks, Company and Product News, Treasuries and Corporate Debt, Dividend, Earnings, Energy and Oil, Financials, Currencies, General News and Opinion, Gold and Metals and Materials, IPO, Legal and Regulation, M&A and Investments, Macro, Markets, Politics, Personnel Change, Stock Commentary, Stock Movement\n",
    "Text:{text}\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kwargs={\"max_new_tokens\":200,\"top_p\":0.95,\"do_sample\":True,\"top_k\":50,\"temperature\":0.1,\"repetition_penalty\":2.0}\n",
    "llm = HuggingFacePipeline.from_model_id(model_id=model_name,task=\"text-generation\",device=-1, pipeline_kwargs=pipeline_kwargs)\n",
    "ending = \",\\nCategory:\"\n",
    "base_prompt = PromptTemplate(input_variables=[\"text\"], template=base_prompt_template)\n",
    "metrics, test_result_df = llm_models.prompt_test(base_prompt, llm, test_data_processed.iloc[:20], ending)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  few shot\n",
    "example_df = pd.read_csv(r'/data/training_data_processed_example.csv')\n",
    "example_df['asExample'] = example_df['asExample'].fillna(0)\n",
    "example_df = example_df[example_df['asExample']!=0]\n",
    "print(example_df.shape,example_df.columns)\n",
    "example_df = example_df[['title', 'label']]\n",
    "example_df.columns = ['text', 'label']\n",
    "example_df=example_df.reset_index(drop=True)\n",
    "example_list = [\n",
    "    f\"Text: {example_df.iloc[i]['text']}\\nCategory: {id2label[example_df.iloc[i]['label']]}\"\n",
    "    for i in range(example_df.shape[0])\n",
    "]\n",
    "examples = \"\\n\".join(example_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Please classify the text into one of the following financial categories:\n",
    "Analyst Update, Fed and Central Banks, Company and Product News, Treasuries and Corporate Debt, Dividend, Earnings, Energy and Oil, Financials, Currencies, General News and Opinion, Gold and Metals and Materials, IPO, Legal and Regulation, M&A and Investments, Macro, Markets, Politics, Personnel Change, Stock Commentary, Stock Movement\n",
    "{examples}\n",
    "Text: {text}\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = train_data_processed['text'].tolist() + test_data_processed[\"text\"].tolist()\n",
    "all_words = set(\" \".join([str(x) for x in all_text]).split())\n",
    "\n",
    "# Get unknown words\n",
    "model_name = 'gpt2'\n",
    "tokenizer1 = GPT2Tokenizer.from_pretrained(model_name)\n",
    "vocab = tokenizer1.get_vocab()\n",
    "unknown_words = [word for word in all_words if word not in vocab]\n",
    "if unknown_words:\n",
    "    num_added_toks = tokenizer1.add_tokens(unknown_words)\n",
    "    print(f\"Added {num_added_toks} tokens to the tokenizer vocabulary.\")\n",
    "    model1 = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "    model1.resize_token_embeddings(len(tokenizer1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kwargs={\"max_new_tokens\":20,\"top_p\":0.95,\"do_sample\":True,\"top_k\":50,\"temperature\":0.1,\"repetition_penalty\":2.0}\n",
    "model1.config.pad_token_id = model1.config.eos_token_id\n",
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model1,\n",
    "    pad_token_id=50256,\n",
    "    tokenizer=tokenizer1,\n",
    "    **pipeline_kwargs,\n",
    "    # max_length=20,\n",
    "    truncation=True,\n",
    ")\n",
    "llm1 = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "ending = \"\\nCategory:\"\n",
    "input_dict = {'examples':examples, 'text':None}\n",
    "metrics, test_result_df = llm_models.prompt_test(prompt_template, input_dict, llm1, test_data_processed.iloc[:20], ending)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_epochs = 4\n",
    "lr_initial_1 = 6e-5\n",
    "weight_decay_1 = 5e-3\n",
    "unfreeze_layer = 2\n",
    "model_name ='distilgpt2'\n",
    "metrics_df_1 = llm_models.fine_tune_gpt(model_name, 'ForSEC', dataset_dict, num_train_epochs, lr_initial_1, weight_decay_1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
